{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb32a80-0e1b-4ddf-b2ff-1fe20611345b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e496b5c5-b8f1-40b3-821c-ed62af8f54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ast\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import neptune\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "from pytorch_faster_rcnn_tutorial.datasets import ObjectDetectionDatasetSingle, ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn_tutorial.faster_RCNN import get_faster_rcnn_resnet\n",
    "from pytorch_faster_rcnn_tutorial.transformations import ComposeDouble\n",
    "from pytorch_faster_rcnn_tutorial.transformations import ComposeSingle\n",
    "from pytorch_faster_rcnn_tutorial.transformations import FunctionWrapperDouble\n",
    "from pytorch_faster_rcnn_tutorial.transformations import FunctionWrapperSingle\n",
    "from pytorch_faster_rcnn_tutorial.transformations import apply_nms, apply_score_threshold\n",
    "from pytorch_faster_rcnn_tutorial.transformations import normalize_01\n",
    "from pytorch_faster_rcnn_tutorial.utils import get_filenames_of_path, collate_single, save_json\n",
    "from pytorch_faster_rcnn_tutorial.visual import DatasetViewer\n",
    "from pytorch_faster_rcnn_tutorial.visual import DatasetViewerSingle\n",
    "from pytorch_faster_rcnn_tutorial.backbone_resnet import ResNetBackbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f582ef-cf8b-4ddd-bfce-e986bfa6a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {'EXPERIMENT': 'HEAD-51',  # experiment name, e.g. Head-42\n",
    "          'OWNER': 'johschmidt42',  # e.g. johndoe55\n",
    "          'INPUT_DIR': 'pytorch_faster_rcnn_tutorial/data/heads/test',  # files to predict\n",
    "          'PREDICTIONS_PATH': 'predictions',  # where to save the predictions\n",
    "          'MODEL_DIR': 'heads',  # load model from checkpoint\n",
    "          'DOWNLOAD': True,  # whether to download from neptune\n",
    "          'DOWNLOAD_PATH': 'model',  # where to save the model if DOWNLOAD is True\n",
    "          'PROJECT': 'Heads',  # Project name\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f8bab4-464b-480b-883e-3e8e5e267ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "inputs = get_filenames_of_path(pathlib.Path(params['INPUT_DIR']))\n",
    "inputs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c30ad2-9fd9-4090-b300-78a36fe83ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "transforms = ComposeSingle([\n",
    "    FunctionWrapperSingle(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperSingle(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f296e5-971c-40bc-a7ae-cdb3f110ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dataset = ObjectDetectionDatasetSingle(inputs=inputs,\n",
    "                                       transform=transforms,\n",
    "                                       use_cache=False,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e02b562-62e3-42a1-abbd-892c3b77f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "dataloader_prediction = DataLoader(dataset=dataset,\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=0,\n",
    "                                   collate_fn=collate_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ca9ab1-70c3-4d8c-895c-780e5b159120",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3MjYwMmIwNy1jMDZlLTRiYTYtODQyZC0zNGRkMmRjYzg2MmUifQ==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618796d3-1009-42ce-8fbc-4e8197a652ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import experiment from neptune\n",
    "project_name = f'{params[\"OWNER\"]}/{params[\"PROJECT\"]}'\n",
    "project = neptune.init(project_qualified_name=project_name, api_token=api_key)  # get project\n",
    "experiment_id = params['EXPERIMENT']  # experiment id\n",
    "experiment = project.get_experiments(id=experiment_id)[0]\n",
    "parameters = experiment.get_parameters()\n",
    "properties = experiment.get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f455a449-db53-4e14-aa41-e2192ce719a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcnn transform\n",
    "transform = GeneralizedRCNNTransform(min_size=int(parameters['MIN_SIZE']),\n",
    "                                     max_size=int(parameters['MAX_SIZE']),\n",
    "                                     image_mean=ast.literal_eval(parameters['IMG_MEAN']),\n",
    "                                     image_std=ast.literal_eval(parameters['IMG_STD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abcea34a-aeb6-4ca2-9208-ac71074819b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dataset\n",
    "datasetviewer = DatasetViewerSingle(dataset, rccn_transform=None)\n",
    "datasetviewer.napari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8277d891-0926-4005-938f-a8caf9646ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (download_path \u001b[39m/\u001b[39m model_name)\u001b[39m.\u001b[39mis_file():\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         experiment\u001b[39m.\u001b[39mdownload_artifact(path\u001b[39m=\u001b[39mmodel_name, destination_dir\u001b[39m=\u001b[39mdownload_path)  \u001b[39m# download model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     model_state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(download_path \u001b[39m/\u001b[39;49m model_name, map_location\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(params[\u001b[39m'\u001b[39m\u001b[39mMODEL_DIR\u001b[39m\u001b[39m'\u001b[39m], map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/faster-rcnn-tutorial/lib/python3.8/site-packages/torch/serialization.py:705\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m     \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[0;32m--> 705\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    706\u001b[0m         \u001b[39mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m    707\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m dispatching to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directly to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m silence this warning)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/faster-rcnn-tutorial/lib/python3.8/site-packages/torch/serialization.py:243\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name_or_buffer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_reader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileReader(name_or_buffer))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "# download model from neptune or load from checkpoint\n",
    "if params['DOWNLOAD']:\n",
    "    download_path = pathlib.Path(os.getcwd()) / params['DOWNLOAD_PATH']\n",
    "    download_path.mkdir(parents=True, exist_ok=True)\n",
    "    model_name = 'best_model.pt'  # that's how I called the best model\n",
    "    # model_name = properties['checkpoint_name']  # logged when called log_model_neptune()\n",
    "    if not (download_path / model_name).is_file():\n",
    "        experiment.download_artifact(path=model_name, destination_dir=download_path)  # download model\n",
    "\n",
    "    model_state_dict = torch.load(download_path / model_name, map_location=torch.device('cpu'))\n",
    "else:\n",
    "    checkpoint = torch.load(params['MODEL_DIR'], map_location=torch.device('cpu'))\n",
    "    model_state_dict = checkpoint['hyper_parameters']['model'].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a78b32-2283-45ad-83c2-11337e4c2505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "model = get_faster_rcnn_resnet(num_classes=int(parameters['CLASSES']),\n",
    "                               backbone_name=ResNetBackbones(parameters['BACKBONE']),  # reverse look-up enum\n",
    "                               anchor_size=ast.literal_eval(parameters['ANCHOR_SIZE']),\n",
    "                               aspect_ratios=ast.literal_eval(parameters['ASPECT_RATIOS']),\n",
    "                               fpn=ast.literal_eval(parameters['FPN']),\n",
    "                               min_size=int(parameters['MIN_SIZE']),\n",
    "                               max_size=int(parameters['MAX_SIZE'])\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d659f25-0d7d-4a97-be15-5795e24f2e71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_state_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load weights\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/zeon/Documents/code/DL/PyTorch-Object-Detection-Faster-RCNN-Tutorial/inference_script.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(model_state_dict)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_state_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# load weights\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59d69e-b9ca-45b3-8320-2a7d4a0e4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference (cpu)\n",
    "model.eval()\n",
    "for sample in dataloader_prediction:\n",
    "    x, x_name = sample\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        pred = {key: value.numpy() for key, value in pred[0].items()}\n",
    "        name = pathlib.Path(x_name[0])\n",
    "        save_dir = pathlib.Path(os.getcwd()) / params['PREDICTIONS_PATH']\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pred_list = {key: value.tolist() for key, value in pred.items()}  # numpy arrays are not serializable -> .tolist()\n",
    "        save_json(pred_list, path=save_dir / name.with_suffix('.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2e424-4308-4586-a2ca-d0349cffc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction files\n",
    "predictions = get_filenames_of_path(pathlib.Path(os.getcwd()) / params['PREDICTIONS_PATH'])\n",
    "predictions.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66697a0b-7989-4e44-8056-b62b70a49bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction dataset\n",
    "iou_threshold = 0.25\n",
    "score_threshold = 0.6\n",
    "\n",
    "transforms_prediction = ComposeDouble([\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01),\n",
    "    FunctionWrapperDouble(apply_nms, input=False, target=True, iou_threshold=iou_threshold),\n",
    "    FunctionWrapperDouble(apply_score_threshold, input=False, target=True, score_threshold=score_threshold)\n",
    "])\n",
    "\n",
    "dataset_prediction = ObjectDetectionDataSet(inputs=inputs,\n",
    "                                            targets=predictions,\n",
    "                                            transform=transforms_prediction,\n",
    "                                            use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb62e53-0e06-4bb5-86a3-8c23d1556ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "color_mapping = {\n",
    "    1: 'red',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50e474-202d-48ac-b5d0-13d69c3b7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions\n",
    "datasetviewer_prediction = DatasetViewer(dataset_prediction, color_mapping)\n",
    "datasetviewer_prediction.napari()\n",
    "# add text properties gui\n",
    "datasetviewer_prediction.gui_text_properties(datasetviewer_prediction.shape_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b26ebc-1df1-4829-9e72-1bd2452976e7",
   "metadata": {},
   "source": [
    "## Experiment with Non-maximum suppression (nms) and score-thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b440cbf-94fa-439c-ac9f-134959617f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment with nms and score-thresholding\n",
    "transforms_prediction = ComposeDouble([\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])\n",
    "\n",
    "dataset_prediction = ObjectDetectionDataSet(inputs=inputs,\n",
    "                                            targets=predictions,\n",
    "                                            transform=transforms_prediction,\n",
    "                                            use_cache=False)\n",
    "\n",
    "color_mapping = {\n",
    "    1: 'red',\n",
    "}\n",
    "\n",
    "datasetviewer_prediction = DatasetViewer(dataset_prediction, color_mapping)\n",
    "datasetviewer_prediction.napari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde50455-2b3b-4530-bf12-fbade6e19bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add score slider\n",
    "# DOES CURRENTLY NOT WORK\n",
    "# datasetviewer_prediction.gui_score_slider(datasetviewer_prediction.shape_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace35a64-c53d-40f5-941e-485e085746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add nms slider\n",
    "# DOES CURRENTLY NOT WORK\n",
    "# datasetviewer_prediction.gui_nms_slider(datasetviewer_prediction.shape_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('faster-rcnn-tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b40717921f7ec431f7e5b57f975a494394ec27ac98ae1509dfe3411e7e51f598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
