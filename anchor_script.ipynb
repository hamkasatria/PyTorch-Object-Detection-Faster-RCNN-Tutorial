{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52b8d4e-fc27-4b77-bfbe-7148c997c506",
   "metadata": {},
   "source": [
    "# AnchorViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9075878f-4244-4e2e-ae0d-273db6294e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "from pytorch_faster_rcnn_module.datasets import ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn_module.transformations import Clip, ComposeDouble\n",
    "from pytorch_faster_rcnn_module.transformations import FunctionWrapperDouble\n",
    "from pytorch_faster_rcnn_module.transformations import normalize_01\n",
    "from pytorch_faster_rcnn_module.utils import get_filenames_of_path\n",
    "from pytorch_faster_rcnn_module.visual import AnchorViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b804c1b0-381a-4a10-bba9-17832edf1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory\n",
    "root = pathlib.Path('pytorch_faster_rcnn_module/data/heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44f9d28-92ff-4a85-a52f-a2ba41654139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'input')\n",
    "targets = get_filenames_of_path(root / 'target')\n",
    "\n",
    "inputs.sort()\n",
    "targets.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f54dfdd4-bc4e-42dd-adb9-8d7451b399f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "mapping = {\n",
    "    'head': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e40e219-62b6-42b9-81a2-c7d867a47dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transforms = ComposeDouble([\n",
    "    Clip(),\n",
    "    # AlbumentationWrapper(albumentation=A.HorizontalFlip(p=0.5)),\n",
    "    # AlbumentationWrapper(albumentation=A.RandomScale(p=0.5, scale_limit=0.5)),\n",
    "    # AlbumentationWrapper(albumentation=A.VerticalFlip(p=0.5)),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178b3597-b7c1-4e0b-a293-5a17a8faeb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset building\n",
    "dataset = ObjectDetectionDataSet(inputs=inputs,\n",
    "                                 targets=targets,\n",
    "                                 transform=transforms,\n",
    "                                 use_cache=False,\n",
    "                                 convert_to_format=None,\n",
    "                                 mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580f5009-cccf-4cca-9e19-368d1be494cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = GeneralizedRCNNTransform(min_size=1024,\n",
    "                                     max_size=1024,\n",
    "                                     image_mean=[0.485, 0.456, 0.406],\n",
    "                                     image_std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba388e24-8102-4b1d-abaa-8a9a5781d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset[0]['x']  # ObjectDetectionDataSet\n",
    "feature_map_size = (512, 32, 32)\n",
    "anchorviewer = AnchorViewer(image=image,\n",
    "                            rcnn_transform=transform,\n",
    "                            feature_map_size=feature_map_size,\n",
    "                            anchor_size=((128, 256, 512),),\n",
    "                            aspect_ratios=((0.5, 1.0, 2.0),)\n",
    "                            )\n",
    "anchorviewer.napari()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv-faster-rcnn': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9fdb926e3011c7254eb0dd1c7c7719351859612423fdf80ee175bc27bfbde0d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
